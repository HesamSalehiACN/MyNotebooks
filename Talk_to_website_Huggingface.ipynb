{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing the packages"
      ],
      "metadata": {
        "id": "Lf_Hgex6adhw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0UYcKiSFFPF"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install unstructured\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken\n",
        "!pip install unstructured[local-inference]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Importing the packages"
      ],
      "metadata": {
        "id": "_H8uSYUPaml_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"Enter Huggingface API Token\"\n",
        "from langchain.text_splitter import CharacterTextSplitter #text splitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings #for using HugginFace models\n",
        "from langchain.vectorstores import FAISS  #facebook vectorizationfrom langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.indexes import VectorstoreIndexCreator #vectorize db index with chromadb\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import UnstructuredURLLoader  #load urls into docoument-loader"
      ],
      "metadata": {
        "id": "o4LA25gIFjXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pulling and loading the URLs"
      ],
      "metadata": {
        "id": "peVZq1xfavDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "urls = [\n",
        "    \"https://towardsdatascience.com/10-machine-learning-methods-that-every-data-scientist-should-know-3cc96e0eeee9\",\n",
        "    \"https://www.analyticssteps.com/blogs/top-6-machine-learning-techniques\"\n",
        "]\n",
        "loader2 = [UnstructuredURLLoader(urls=urls)]"
      ],
      "metadata": {
        "id": "77o_RlDtHsxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Embedding and text splitting"
      ],
      "metadata": {
        "id": "Nke1mLOZjzs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index2 = VectorstoreIndexCreator(\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(loader2)"
      ],
      "metadata": {
        "id": "xkKJR42CHsnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Creating the chain/agent"
      ],
      "metadata": {
        "id": "92kjT0Tokc2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm2=HuggingFaceHub(repo_id=\"declare-lab/flan-alpaca-large\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
        "# Alternative LLMs:\n",
        "# llm=HuggingFaceHub(repo_id=\"MBZUAI/LaMini-Flan-T5-783M\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
        "# llm2=HuggingFaceHub(repo_id=\"OpenAssistant/falcon-40b-megacode2-oasst\", model_kwargs={\"temperature\":0, \"max_length\":512})\n",
        "from langchain.chains import RetrievalQA\n",
        "chain = RetrievalQA.from_chain_type(llm=llm2,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=index2.vectorstore.as_retriever(),\n",
        "                                    input_key=\"question\")"
      ],
      "metadata": {
        "id": "gOof-nSlIZtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Query the data\n",
        "Remember that the the first run may be a little slow. If it takes more than 5 minutes means that most probably an error from the Hugging Face API will occur. Stop the run of the cell and try to run another one, and then run it again."
      ],
      "metadata": {
        "id": "G765x5Oekh2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run('Explain about regression technique')"
      ],
      "metadata": {
        "id": "_21rTIeZI8QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xz0J3prVrt3a"
      }
    }
  ]
}